{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6zUpSXn6FoNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50543c83-3296-4321-9c61-ca557d9b9e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.9.0+cpu\n"
          ]
        }
      ],
      "source": [
        "#Did I mention that calc is short for calculator\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Simple feedforward network used as a function approximator.\n",
        "    This architecture is intentionally small to make failure modes visible.\n",
        "    ReLU introduces non-linearity; final layer is linear for regression output.\n",
        "\"\"\"\n",
        "class MathNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "N2Zk0hS5Fpld"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(operation, epochs=1501):\n",
        "    model = MathNet()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    \"\"\"\n",
        "        Training data is synthetically generated.\n",
        "        Inputs are sampled from a limited range to highlight extrapolation failure.\n",
        "        Neural networks interpolate well inside this range, but degrade outside it.\n",
        "    \"\"\"\n",
        "    X = torch.rand(8000, 2) * 20 - 10  # [-10, 10]\n",
        "\n",
        "    \"\"\"\n",
        "        Addition and subtraction are linear functions.\n",
        "        Linear functions extrapolate smoothly, so these operations perform well\n",
        "        even outside the training range.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "        Multiplication is nonlinear.\n",
        "        The network learns a curved surface approximation, which degrades rapidly\n",
        "        when inputs exceed the training distribution.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "        Division is numerically unstable near zero.\n",
        "        To avoid exploding gradients and unbounded targets,\n",
        "        the denominator is sampled away from zero.\n",
        "    \"\"\"\n",
        "    if operation == \"add\":\n",
        "        y = X[:, 0] + X[:, 1]\n",
        "\n",
        "    elif operation == \"sub\":\n",
        "        y = X[:, 0] - X[:, 1]\n",
        "\n",
        "    elif operation == \"mul\":\n",
        "        y = X[:, 0] * X[:, 1]\n",
        "\n",
        "    elif operation == \"div\":\n",
        "        b = torch.rand(len(X)) * 9 + 1\n",
        "        sign = torch.randint(0, 2, (len(X),)) * 2 - 1\n",
        "        X[:, 1] = b * sign\n",
        "        y = (X[:, 0] / X[:, 1]) / 10\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unknown operation\")\n",
        "\n",
        "    y = y.unsqueeze(1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 300 == 0:\n",
        "            print(f\"{operation.upper()} | Epoch {epoch} | Loss {loss.item():.4f}\")\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "shiOELRPFu7U"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Standard supervised regression training loop.\n",
        "    Mean Squared Error is used to emphasize large deviations,\n",
        "    which makes extrapolation failures more visible.\n",
        "\"\"\"\n",
        "add_net = train_model(\"add\")\n",
        "sub_net = train_model(\"sub\")\n",
        "mul_net = train_model(\"mul\")\n",
        "div_net = train_model(\"div\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42b-l7-JFxQl",
        "outputId": "81f63e64-1a26-4b9e-e65d-4391b192e4e3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADD | Epoch 0 | Loss 59.9746\n",
            "ADD | Epoch 300 | Loss 0.0135\n",
            "ADD | Epoch 600 | Loss 0.0051\n",
            "ADD | Epoch 900 | Loss 0.0029\n",
            "ADD | Epoch 1200 | Loss 0.0020\n",
            "ADD | Epoch 1500 | Loss 0.0015\n",
            "SUB | Epoch 0 | Loss 64.7457\n",
            "SUB | Epoch 300 | Loss 0.0487\n",
            "SUB | Epoch 600 | Loss 0.0119\n",
            "SUB | Epoch 900 | Loss 0.0040\n",
            "SUB | Epoch 1200 | Loss 0.0016\n",
            "SUB | Epoch 1500 | Loss 0.0009\n",
            "MUL | Epoch 0 | Loss 1091.2910\n",
            "MUL | Epoch 300 | Loss 46.6114\n",
            "MUL | Epoch 600 | Loss 38.4499\n",
            "MUL | Epoch 900 | Loss 19.4839\n",
            "MUL | Epoch 1200 | Loss 5.6922\n",
            "MUL | Epoch 1500 | Loss 1.8629\n",
            "DIV | Epoch 0 | Loss 0.5129\n",
            "DIV | Epoch 300 | Loss 0.0050\n",
            "DIV | Epoch 600 | Loss 0.0017\n",
            "DIV | Epoch 900 | Loss 0.0007\n",
            "DIV | Epoch 1200 | Loss 0.0004\n",
            "DIV | Epoch 1500 | Loss 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "models = {\n",
        "    \"+\": add_net,\n",
        "    \"-\": sub_net,\n",
        "    \"*\": mul_net,\n",
        "    \"/\": div_net\n",
        "}\n",
        "\n",
        "def goofy_calc(a, b, op):\n",
        "    x = torch.tensor([[a, b]], dtype=torch.float32)\n",
        "    pred = models[op](x).item()\n",
        "    # Division outputs were normalized during training,\n",
        "    # so we undo the scaling here to recover the original magnitude.\n",
        "    if op == \"/\":\n",
        "        pred *= 10\n",
        "\n",
        "    if op == \"+\": true_val = a + b\n",
        "    elif op == \"-\": true_val = a - b\n",
        "    elif op == \"*\": true_val = a * b\n",
        "    elif op == \"/\":\n",
        "        true_val = a / b if b != 0 else float('inf')\n",
        "\n",
        "    if true_val == float('inf'):\n",
        "        confidence = 0.0\n",
        "    else:\n",
        "        # Confidence is derived from prediction error.\n",
        "        # Lower error implies higher confidence, but this does NOT account\n",
        "        # for out-of-distribution inputs, which makes confidence misleading.\n",
        "        ratio = min(abs(true_val), abs(pred)) / max(abs(true_val), abs(pred))\n",
        "        confidence = ratio * 100\n",
        "\n",
        "    return round(pred, 4), confidence\n"
      ],
      "metadata": {
        "id": "leUbu6wqF0MI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def goofy_comment(expr, result, confidence):\n",
        "    if confidence < 50:\n",
        "        templates = [\n",
        "            \"Uhh… I think it's {r}, but please don't quote me.\",\n",
        "            \"Math is scary, but {r} feels emotionally correct.\",\n",
        "            \"I regret everything, especially this answer: {r}.\"\n",
        "        ]\n",
        "    elif confidence < 75:\n",
        "        templates = [\n",
        "            \"{r} seems about right, give or take a universe.\",\n",
        "            \"I'm not 100% sure, but {r} has good vibes.\",\n",
        "            \"Let's go with {r} and walk away confidently.\"\n",
        "        ]\n",
        "    else:\n",
        "        templates = [\n",
        "            \"{r}. Final answer. No questions.\",\n",
        "            \"{r} is obviously correct and I refuse to elaborate.\",\n",
        "            \"If {r} is wrong, then math is wrong.\"\n",
        "        ]\n",
        "\n",
        "    return random.choice(templates).format(r=result)\n"
      ],
      "metadata": {
        "id": "DoSqOIHrcjP8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    (100, 100, \"+\"),\n",
        "    (100, 100, \"/\"),\n",
        "    (35, 21, \"*\"),\n",
        "    (10, 4, \"-\")\n",
        "]\n",
        "\n",
        "for a, b, op in tests:\n",
        "    res, conf = goofy_calc(a, b, op)\n",
        "\n",
        "    expr = f\"{a} {op} {b}\"   # <-- THIS WAS MISSING\n",
        "\n",
        "    comment = goofy_comment(expr, res, conf)\n",
        "\n",
        "\n",
        "    print(f\"{expr} = {res}  (confidence: {conf:.1f}%)\")\n",
        "    print(comment)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDf8CeMkWNpk",
        "outputId": "9cb02355-29e1-4993-9c92-ade2ace103d9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 + 100 = 198.0472  (confidence: 99.0%)\n",
            "LLM says: 198.0472. Final answer. No questions.\n",
            "\n",
            "100 / 100 = 2.9248  (confidence: 34.2%)\n",
            "LLM says: Uhh… I think it's 2.9248, but please don't quote me.\n",
            "\n",
            "35 * 21 = 245.3125  (confidence: 33.4%)\n",
            "LLM says: Uhh… I think it's 245.3125, but please don't quote me.\n",
            "\n",
            "10 - 4 = 6.0928  (confidence: 98.5%)\n",
            "LLM says: 6.0928 is obviously correct and I refuse to elaborate.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  print(\"Do you really wanna do math?(Y/N)\")\n",
        "  inp = input(\":\")\n",
        "  if inp.upper() ==\"Y\":\n",
        "    try:\n",
        "        a1 = int(input(\"Enter the first number: \"))\n",
        "        a2 = int(input(\"Enter the second number: \"))\n",
        "    except ValueError:\n",
        "        print(\"Numbers. I asked for numbers.\\n\")\n",
        "        continue\n",
        "    sign=input(\"Enter the operation (+,-,/,*):\")\n",
        "    if sign not in [\"+\",\"-\",\"/\",\"*\"]:\n",
        "      print(\"Invalid operation, now type it all from start >:)\")\n",
        "      continue\n",
        "    res, conf = goofy_calc(a1, a2, sign)\n",
        "    expr = f\"{a1} {sign} {a2}\"   # <-- THIS WAS MISSING\n",
        "\n",
        "    comment = goofy_comment(expr, res, conf)\n",
        "\n",
        "    print( comment)\n",
        "    print()\n",
        "  elif inp.upper()==\"N\":\n",
        "    print(\"Great Choice! I hate math two!\")#intentional\n",
        "    print()\n",
        "    break\n",
        "  else:\n",
        "    print(\"Stop entering invalid input weezo.\")\n",
        "    print()\n",
        "\n",
        "#\n",
        "#     Summary:\n",
        "#     This project demonstrates why neural networks are poor tools\n",
        "#     for exact symbolic computation. They learn patterns from data,\n",
        "#     not rules, and their confidence does not imply correctness,\n",
        "#     especially outside the training distribution.\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyUUM833cxAB",
        "outputId": "db39c884-934c-41df-d547-6ded5211e267"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you really wanna do math?(Y/N)\n",
            ":n\n",
            "Great Choice! I hate math two!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
